{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5367d6c5-b847-4e6b-b165-0876d2a91181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: /Users/danielvillafuerte/weather-aware-trajectory-prediction\n",
      "Data path exists: True\n"
     ]
    }
   ],
   "source": [
    "# Basic imports and general setup\n",
    "import os, sys, importlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Had some issues with the file paths just bc of where I ran the notebook from but fixed by finding the root\n",
    "repo_root = Path.cwd()\n",
    "for up in [repo_root, repo_root.parent, repo_root.parent.parent]:\n",
    "    if (up / \"src\").exists():\n",
    "        repo_root = up\n",
    "        break\n",
    "sys.path.insert(0, str(repo_root))\n",
    "\n",
    "# Importing geo module for coordinate translation. My Lat/Lon/Alt to ENU is in this geo.\n",
    "import src.geo as geo \n",
    "importlib.invalidate_caches()\n",
    "geo = importlib.reload(geo)\n",
    "\n",
    "# Create clean alias for the main function we'll use\n",
    "latlonalt_to_enu = geo.latlonalt_to_enu\n",
    "\n",
    "#Making my notebook look cool\n",
    "print(f\"Repo root: {repo_root}\")\n",
    "print(f\"Data path exists: {(repo_root / 'data' / 'raw').exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0f9e5f3-facf-4cfe-a36f-682ac635da8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1,561,361 rows\n",
      "After filtering: 1,109,800 rows with valid position data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>icao24</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>velocity</th>\n",
       "      <th>heading</th>\n",
       "      <th>vertrate</th>\n",
       "      <th>callsign</th>\n",
       "      <th>onground</th>\n",
       "      <th>alert</th>\n",
       "      <th>spi</th>\n",
       "      <th>squawk</th>\n",
       "      <th>baroaltitude</th>\n",
       "      <th>geoaltitude</th>\n",
       "      <th>lastposupdate</th>\n",
       "      <th>lastcontact</th>\n",
       "      <th>alt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-12 00:00:00</td>\n",
       "      <td>4062d5</td>\n",
       "      <td>52.741870</td>\n",
       "      <td>-0.567287</td>\n",
       "      <td>172.119770</td>\n",
       "      <td>295.492795</td>\n",
       "      <td>-9.10336</td>\n",
       "      <td>EXS46B</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3244.0</td>\n",
       "      <td>9212.58</td>\n",
       "      <td>9372.60</td>\n",
       "      <td>1.497226e+09</td>\n",
       "      <td>1.497226e+09</td>\n",
       "      <td>9372.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-06-12 00:00:10</td>\n",
       "      <td>a9f4c6</td>\n",
       "      <td>38.733215</td>\n",
       "      <td>-90.131836</td>\n",
       "      <td>150.662723</td>\n",
       "      <td>83.530180</td>\n",
       "      <td>13.00480</td>\n",
       "      <td>3536</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1734.0</td>\n",
       "      <td>1905.00</td>\n",
       "      <td>1981.20</td>\n",
       "      <td>1.497226e+09</td>\n",
       "      <td>1.497226e+09</td>\n",
       "      <td>1981.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-06-12 00:00:10</td>\n",
       "      <td>a0b20e</td>\n",
       "      <td>35.164902</td>\n",
       "      <td>-104.443939</td>\n",
       "      <td>221.811287</td>\n",
       "      <td>268.405170</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>FDX556</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7677.0</td>\n",
       "      <td>11574.78</td>\n",
       "      <td>12146.28</td>\n",
       "      <td>1.497226e+09</td>\n",
       "      <td>1.497226e+09</td>\n",
       "      <td>12146.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-06-12 00:00:10</td>\n",
       "      <td>85c970</td>\n",
       "      <td>35.337385</td>\n",
       "      <td>138.482724</td>\n",
       "      <td>203.732815</td>\n",
       "      <td>264.203031</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>ANA791</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2355.0</td>\n",
       "      <td>7924.80</td>\n",
       "      <td>8161.02</td>\n",
       "      <td>1.497226e+09</td>\n",
       "      <td>1.497226e+09</td>\n",
       "      <td>8161.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-06-12 00:00:10</td>\n",
       "      <td>a0ce85</td>\n",
       "      <td>39.907278</td>\n",
       "      <td>-104.448242</td>\n",
       "      <td>130.236658</td>\n",
       "      <td>73.712637</td>\n",
       "      <td>8.12800</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>625.0</td>\n",
       "      <td>6515.10</td>\n",
       "      <td>3154.68</td>\n",
       "      <td>1.497225e+09</td>\n",
       "      <td>1.497226e+09</td>\n",
       "      <td>3154.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time  icao24        lat         lon    velocity     heading  \\\n",
       "0 2017-06-12 00:00:00  4062d5  52.741870   -0.567287  172.119770  295.492795   \n",
       "1 2017-06-12 00:00:10  a9f4c6  38.733215  -90.131836  150.662723   83.530180   \n",
       "2 2017-06-12 00:00:10  a0b20e  35.164902 -104.443939  221.811287  268.405170   \n",
       "5 2017-06-12 00:00:10  85c970  35.337385  138.482724  203.732815  264.203031   \n",
       "6 2017-06-12 00:00:10  a0ce85  39.907278 -104.448242  130.236658   73.712637   \n",
       "\n",
       "   vertrate callsign  onground  alert    spi  squawk  baroaltitude  \\\n",
       "0  -9.10336   EXS46B     False  False  False  3244.0       9212.58   \n",
       "1  13.00480     3536     False  False  False  1734.0       1905.00   \n",
       "2   0.00000   FDX556     False  False  False  7677.0      11574.78   \n",
       "5   0.00000   ANA791     False  False  False  2355.0       7924.80   \n",
       "6   8.12800              False  False  False   625.0       6515.10   \n",
       "\n",
       "   geoaltitude  lastposupdate   lastcontact       alt  \n",
       "0      9372.60   1.497226e+09  1.497226e+09   9372.60  \n",
       "1      1981.20   1.497226e+09  1.497226e+09   1981.20  \n",
       "2     12146.28   1.497226e+09  1.497226e+09  12146.28  \n",
       "5      8161.02   1.497226e+09  1.497226e+09   8161.02  \n",
       "6      3154.68   1.497225e+09  1.497226e+09   3154.68  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First step: Loading and starting the preprocessing\n",
    "# Load the raw data\n",
    "DATA_PATH = repo_root / \"data\" / \"raw\" / \"06_12_17.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(f\"Loaded {len(df):,} rows\")\n",
    "\n",
    "# Time conversion and callsign cleanup\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"], unit=\"s\", errors=\"coerce\")\n",
    "df[\"callsign\"] = df.get(\"callsign\", \"\").fillna(\"\").str.strip()\n",
    "\n",
    "# Drop rows without position and time (essential for trajectory). Also realized that there are two opts for Altitude: baroaltitude and geoaltitude\n",
    "df = df.dropna(subset=[\"lat\", \"lon\", \"time\"]).copy()\n",
    "\n",
    "# Create altitude column with fallback strategy\n",
    "# Prefer geoaltitude, fallback to baroaltitude, then 0. Can imagine doing it this way would cause any issues.\n",
    "if \"geoaltitude\" in df.columns:\n",
    "    df[\"alt\"] = df[\"geoaltitude\"]\n",
    "    if \"baroaltitude\" in df.columns:\n",
    "        df[\"alt\"] = df[\"alt\"].fillna(df[\"baroaltitude\"])\n",
    "elif \"baroaltitude\" in df.columns:\n",
    "    df[\"alt\"] = df[\"baroaltitude\"]\n",
    "else:\n",
    "    df[\"alt\"] = 0.0\n",
    "df[\"alt\"] = df[\"alt\"].fillna(0.0)\n",
    "\n",
    "print(f\"After filtering: {len(df):,} rows with valid position data\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c58b3de7-4f75-41bc-8b90-a68a88243e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 9 columns: ['time', 'icao24', 'lat', 'lon', 'alt', 'callsign', 'velocity', 'heading', 'vertrate']\n",
      "Identified 7070 unique flight segments\n",
      "Median gap between points: 10.0 seconds\n"
     ]
    }
   ],
   "source": [
    "# Keep Essential Columns & start Flight Segmentation\n",
    "# Keep only columns relevant for trajectory prediction\n",
    "essential_cols = ['time', 'icao24', 'lat', 'lon', 'alt', 'callsign']\n",
    "optional_cols = ['velocity', 'heading', 'vertrate']  # Keep for potential validation but not really super necessary, I guess we will see\n",
    "\n",
    "keep_cols = essential_cols + [c for c in optional_cols if c in df.columns] #list compehension to keep the optional if exists\n",
    "df = df[keep_cols].copy()\n",
    "\n",
    "print(f\"Kept {len(df.columns)} columns: {list(df.columns)}\")\n",
    "\n",
    "# Sort by aircraft ID and time for proper segmentation between different flights\n",
    "df = df.sort_values(['icao24', 'time']).reset_index(drop=True)\n",
    "\n",
    "# Calculate time gaps between consecutive points for same aircraft\n",
    "df['gap_s'] = df.groupby('icao24')['time'].diff().dt.total_seconds().fillna(0)\n",
    "\n",
    "# Create flight_id: new flight when aircraft changes OR gap > 10 minutes\n",
    "df['flight_id'] = ((df['icao24'] != df['icao24'].shift()) | \n",
    "                   (df['gap_s'] > 600)).cumsum()\n",
    "\n",
    "print(f\"Identified {df['flight_id'].nunique()} unique flight segments\")\n",
    "print(f\"Median gap between points: {df[df['gap_s'] > 0]['gap_s'].median():.1f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10bc9c34-2c0a-4833-98ad-6b11107983c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 5492 continuous runs\n",
      "Total rows: 1,038,555\n",
      "Average run length: 189.1 points\n"
     ]
    }
   ],
   "source": [
    "# Filtering for Continuous Flight Segments\n",
    "def keep_consecutive_runs(df, min_len=60, max_gap_s=120):\n",
    "    \"\"\"\n",
    "    Keep only continuous, valid segments within each flight:\n",
    "      - valid = lat, lon, alt present\n",
    "      - new run when invalid OR time gap > max_gap_s\n",
    "      - keep runs with at least min_len consecutive valid samples\n",
    "    \"\"\"\n",
    "    d = df.sort_values([\"flight_id\", \"time\"]).copy()\n",
    "    d[\"valid\"] = d[[\"lat\", \"lon\", \"alt\"]].notna().all(axis=1)\n",
    "    d[\"dt\"] = d.groupby(\"flight_id\")[\"time\"].diff().dt.total_seconds().fillna(0)\n",
    "\n",
    "    # Mark breaks: invalid data OR gap too large\n",
    "    break_flag = (~d[\"valid\"]) | (d[\"dt\"] > max_gap_s)\n",
    "    d[\"run_id\"] = break_flag.groupby(d[\"flight_id\"]).cumsum()\n",
    "\n",
    "    # Keep only valid points\n",
    "    d_valid = d[d[\"valid\"]].copy()\n",
    "    \n",
    "    # Count consecutive valid points per run\n",
    "    run_sizes = d_valid.groupby([\"flight_id\", \"run_id\"]).size()\n",
    "    keeps = run_sizes[run_sizes >= min_len].reset_index()[[\"flight_id\", \"run_id\"]]\n",
    "    \n",
    "    # Filter to keep only long-enough runs\n",
    "    out = d_valid.merge(keeps, on=[\"flight_id\", \"run_id\"], how=\"inner\")\n",
    "    return out.drop(columns=[\"valid\"])\n",
    "\n",
    "# Apply filtering\n",
    "df_runs = keep_consecutive_runs(df, min_len=60, max_gap_s=120).copy()\n",
    "df_runs = df_runs.sort_values([\"flight_id\", \"run_id\", \"time\"]).reset_index(drop=True)\n",
    "\n",
    "print(f\"Kept {df_runs.groupby(['flight_id', 'run_id']).ngroups} continuous runs\")\n",
    "print(f\"Total rows: {len(df_runs):,}\")\n",
    "print(f\"Average run length: {df_runs.groupby(['flight_id', 'run_id']).size().mean():.1f} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "550e6356-05f4-423b-adf6-1b8f10907c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max E at origin: 0.00e+00 m\n",
      "Max N at origin: 0.00e+00 m\n",
      "Max U at origin: 0.00e+00 m\n",
      "\n",
      "Sample ENU values (first 5 runs):\n",
      "                             E                           N                \\\n",
      "                           min           max           min           max   \n",
      "flight_id run_id                                                           \n",
      "1         0      -7.065782e-12  1.625722e-10 -2.183793e-10  8.848450e-10   \n",
      "3         0       0.000000e+00  3.535112e+04  0.000000e+00  2.660262e+04   \n",
      "          1       0.000000e+00  4.392011e+05  0.000000e+00  2.691027e+05   \n",
      "4         0       0.000000e+00  4.690840e+05 -1.286783e+05  0.000000e+00   \n",
      "7         0      -2.777987e+05  0.000000e+00 -3.867002e+05  0.000000e+00   \n",
      "\n",
      "                             U            \n",
      "                           min       max  \n",
      "flight_id run_id                          \n",
      "1         0      -12192.000000  0.000000  \n",
      "3         0        -183.640069  5.794543  \n",
      "          1      -20941.032764  0.000000  \n",
      "4         0      -18545.243681  0.000000  \n",
      "7         0      -29577.919662  0.000000  \n"
     ]
    }
   ],
   "source": [
    "# Convert to Local ENU Coordinates finally using our geo\n",
    "# Convert each run to ENU with origin at first point\n",
    "runs = []\n",
    "for (fid, rid), g in df_runs.groupby([\"flight_id\", \"run_id\"], sort=False):\n",
    "    g = g.sort_values(\"time\").copy()\n",
    "    \n",
    "    # Use first point as anchor/origin cause this is how ENU works \n",
    "    lat0, lon0, alt0 = g.iloc[0][[\"lat\", \"lon\", \"alt\"]]\n",
    "    \n",
    "    # Convert entire trajectory to ENU\n",
    "    E, N, U = latlonalt_to_enu(\n",
    "        g[\"lat\"].to_numpy(),\n",
    "        g[\"lon\"].to_numpy(),\n",
    "        g[\"alt\"].to_numpy(),\n",
    "        float(lat0), float(lon0), float(alt0)\n",
    "    )\n",
    "    \n",
    "    g[\"E\"], g[\"N\"], g[\"U\"] = E, N, U\n",
    "    runs.append(g)\n",
    "\n",
    "df_runs = pd.concat(runs, ignore_index=True)\n",
    "del runs  # Free memory\n",
    "\n",
    "# Verify first point of each run is at origin\n",
    "first_points = df_runs.groupby([\"flight_id\", \"run_id\"]).first()[[\"E\", \"N\", \"U\"]]\n",
    "print(f\"Max E at origin: {first_points['E'].abs().max():.2e} m\")\n",
    "print(f\"Max N at origin: {first_points['N'].abs().max():.2e} m\") \n",
    "print(f\"Max U at origin: {first_points['U'].abs().max():.2e} m\")\n",
    "print(\"\\nSample ENU values (first 5 runs):\")\n",
    "print(df_runs.groupby([\"flight_id\", \"run_id\"])[[\"E\", \"N\", \"U\"]].agg(['min', 'max']).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b24e44d-26f6-4ce1-a566-d761d05024ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run statistics summary:\n",
      "       duration_min  max_dist_km  alt_change_km  avg_speed_kmh\n",
      "count       5492.00      5492.00        5492.00        5492.00\n",
      "mean          31.39       294.54          14.85         503.71\n",
      "std           16.15       258.21          19.08         295.99\n",
      "min            9.83         0.00           0.00           0.00\n",
      "25%           17.67        86.19           2.82         267.31\n",
      "50%           27.67       223.47           7.77         545.73\n",
      "75%           43.50       439.89          19.16         733.84\n",
      "max           59.67      2801.96         574.49        6226.57\n",
      "\n",
      "Runs with issues: 2156 out of 5492\n",
      "\n",
      "Sample problematic runs:\n",
      "    flight_id  run_id  duration_min  avg_speed_kmh  alt_change_km  \\\n",
      "0           1       0     59.666667   1.122426e-12      12.192000   \n",
      "2           3       1     31.833333   9.708432e+02      20.941033   \n",
      "3           4       0     36.166667   8.069530e+02      18.545244   \n",
      "4           7       0     47.666667   5.993369e+02      29.577920   \n",
      "5          10       0     54.166667   8.157791e+02      41.556722   \n",
      "7          12       0     24.166667   6.985551e+02      15.029855   \n",
      "8          13       0     35.833333   8.468840e+02      20.082872   \n",
      "10         16       0     54.000000   8.303494e+02      43.637365   \n",
      "11         18       0     45.833333   8.010190e+02      29.048557   \n",
      "13         20       0     44.000000   6.086785e+02      27.553883   \n",
      "\n",
      "                   issues  \n",
      "0               too_slow   \n",
      "2   excessive_alt_change   \n",
      "3   excessive_alt_change   \n",
      "4   excessive_alt_change   \n",
      "5   excessive_alt_change   \n",
      "7   excessive_alt_change   \n",
      "8   excessive_alt_change   \n",
      "10  excessive_alt_change   \n",
      "11  excessive_alt_change   \n",
      "13  excessive_alt_change   \n"
     ]
    }
   ],
   "source": [
    "# Data Quality Check\n",
    "# Calculate statistics for each run to identify potential issues\n",
    "gb = df_runs.groupby([\"flight_id\", \"run_id\"], sort=False)\n",
    "\n",
    "# First, let's add dt column if not present\n",
    "df_runs[\"dt\"] = gb[\"time\"].diff().dt.total_seconds().fillna(10)\n",
    "\n",
    "run_stats = gb.agg(\n",
    "    duration_min=(\"time\", lambda x: (x.max() - x.min()).total_seconds() / 60),\n",
    "    n_points=(\"time\", \"count\"),\n",
    "    E_range=(\"E\", lambda x: x.max() - x.min()),\n",
    "    N_range=(\"N\", lambda x: x.max() - x.min()),\n",
    "    alt_change_km=(\"U\", lambda x: (x.max() - x.min()) / 1000),\n",
    "    cadence_s=(\"dt\", \"median\")\n",
    ").reset_index()\n",
    "\n",
    "# Calculate approximate max distance from origin\n",
    "run_stats[\"max_dist_km\"] = np.sqrt(run_stats[\"E_range\"]**2 + run_stats[\"N_range\"]**2) / 1000\n",
    "\n",
    "# Flag potentially problematic runs\n",
    "run_stats[\"avg_speed_kmh\"] = run_stats[\"max_dist_km\"] / (run_stats[\"duration_min\"] / 60)\n",
    "run_stats[\"issues\"] = \"\"\n",
    "run_stats.loc[run_stats[\"avg_speed_kmh\"] > 1200, \"issues\"] += \"high_speed \"\n",
    "run_stats.loc[run_stats[\"avg_speed_kmh\"] < 50, \"issues\"] += \"too_slow \"\n",
    "run_stats.loc[run_stats[\"alt_change_km\"] > 15, \"issues\"] += \"excessive_alt_change \"\n",
    "\n",
    "print(\"Run statistics summary:\")\n",
    "print(run_stats[[\"duration_min\", \"max_dist_km\", \"alt_change_km\", \"avg_speed_kmh\"]].describe().round(2))\n",
    "print(f\"\\nRuns with issues: {(run_stats['issues'] != '').sum()} out of {len(run_stats)}\")\n",
    "print(\"\\nSample problematic runs:\")\n",
    "problem_runs = run_stats[run_stats[\"issues\"] != \"\"].head(10)\n",
    "if len(problem_runs) > 0:\n",
    "    print(problem_runs[[\"flight_id\", \"run_id\", \"duration_min\", \"avg_speed_kmh\", \"alt_change_km\", \"issues\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ee1ec68-ca44-48a7-abf3-16dee2f86fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kinematics statistics after outlier handling:\n",
      "               vE          vN          vU       speed   turn_rate\n",
      "count  1025788.00  1027937.00  1031965.00  1022955.00  1033063.00\n",
      "mean         2.93       10.24       -5.93      142.11        0.00\n",
      "std        148.03      112.37       19.04      118.59        0.06\n",
      "min       -679.99     -679.96     -676.28        0.00       -0.31\n",
      "25%        -87.52      -25.94      -10.67        0.00       -0.00\n",
      "50%          0.00        0.00       -2.15      167.77        0.00\n",
      "75%         89.47       65.08        0.00      232.55        0.00\n",
      "max        679.89      679.77      677.35      961.38        0.31\n",
      "\n",
      "Velocity NaN fraction: 1.50%\n",
      "Turn rate NaN fraction: 0.53%\n"
     ]
    }
   ],
   "source": [
    "# Compute Kinematics with Outlier Handling\n",
    "# Calculate velocities and turn rates from ENU positions\n",
    "gb = df_runs.groupby([\"flight_id\", \"run_id\"], sort=False)\n",
    "\n",
    "# Time differences\n",
    "df_runs[\"dt\"] = gb[\"time\"].diff().dt.total_seconds()\n",
    "df_runs[\"dt\"] = df_runs[\"dt\"].replace(0, np.nan)  # Avoid division by zero\n",
    "\n",
    "# Position differences\n",
    "for c in [\"E\", \"N\", \"U\"]:\n",
    "    df_runs[f\"d{c}\"] = gb[c].diff()\n",
    "\n",
    "# Velocities (m/s)\n",
    "df_runs[\"vE\"] = df_runs[\"dE\"] / df_runs[\"dt\"]\n",
    "df_runs[\"vN\"] = df_runs[\"dN\"] / df_runs[\"dt\"]\n",
    "df_runs[\"vU\"] = df_runs[\"dU\"] / df_runs[\"dt\"]\n",
    "\n",
    "# Cap unrealistic velocities (Mach 2 = ~680 m/s is a reasonable upper limit)\n",
    "MAX_VELOCITY = 680  # m/s\n",
    "for v in [\"vE\", \"vN\", \"vU\"]:\n",
    "    df_runs.loc[df_runs[v].abs() > MAX_VELOCITY, v] = np.nan\n",
    "\n",
    "# Speed and heading\n",
    "df_runs[\"speed\"] = np.sqrt(df_runs[\"vE\"]**2 + df_runs[\"vN\"]**2 + df_runs[\"vU\"]**2)\n",
    "df_runs[\"heading_rad\"] = np.arctan2(df_runs[\"vE\"], df_runs[\"vN\"])\n",
    "\n",
    "# Turn rate (using unwrapped heading to handle discontinuities)\n",
    "df_runs[\"heading_unwrapped\"] = gb[\"heading_rad\"].transform(lambda x: np.unwrap(x.fillna(0)))\n",
    "df_runs[\"turn_rate\"] = gb[\"heading_unwrapped\"].diff() / df_runs[\"dt\"]\n",
    "\n",
    "# Cap unrealistic turn rates (>0.5 rad/s = ~29 deg/s is extreme)\n",
    "df_runs.loc[df_runs[\"turn_rate\"].abs() > 0.5, \"turn_rate\"] = np.nan\n",
    "\n",
    "print(\"Kinematics statistics after outlier handling:\")\n",
    "print(df_runs[[\"vE\", \"vN\", \"vU\", \"speed\", \"turn_rate\"]].describe().round(2))\n",
    "print(f\"\\nVelocity NaN fraction: {df_runs['speed'].isna().mean():.2%}\")\n",
    "print(f\"Turn rate NaN fraction: {df_runs['turn_rate'].isna().mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3e3eec39-169b-4f03-b3fe-606a5006427c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_rows          1.038555e+06\n",
      "E_nonzero_nonNaN    9.981860e+05\n",
      "E_pct               9.611296e+01\n",
      "N_nonzero_nonNaN    9.980340e+05\n",
      "N_pct               9.609833e+01\n",
      "U_nonzero_nonNaN    1.008920e+06\n",
      "U_pct               9.714652e+01\n",
      "dtype: float64\n",
      "total_rows                  1.038555e+06\n",
      "valid_rows                  1.038555e+06\n",
      "valid_pct                   1.000000e+02\n",
      "any_nonzero_rows            1.016795e+06\n",
      "any_nonzero_pct_of_valid    9.790478e+01\n",
      "all_nonzero_rows            9.909490e+05\n",
      "all_nonzero_pct_of_valid    9.541613e+01\n",
      "ignored_first_rows          5.335000e+03\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Quality summaries (same helpers you wrote)\n",
    "def enu_counts(df: pd.DataFrame, eps: float = 1e-6):\n",
    "    total = len(df)\n",
    "    out = {\"total_rows\": total}\n",
    "    for c in (\"E\",\"N\",\"U\"):\n",
    "        mask = df[c].notna() & (df[c].abs() > eps)\n",
    "        cnt = int(mask.sum())\n",
    "        out[f\"{c}_nonzero_nonNaN\"] = cnt\n",
    "        out[f\"{c}_pct\"] = (cnt/total*100.0) if total else 0.0\n",
    "    return pd.Series(out)\n",
    "\n",
    "def enu_row_summary(df: pd.DataFrame, eps: float = 1e-6, ignore_first_per_flight: bool = True):\n",
    "    needed = {\"E\",\"N\",\"U\"}\n",
    "    if not needed.issubset(df.columns):\n",
    "        raise KeyError(\"DataFrame must have E, N, U columns.\")\n",
    "    valid = df[[\"E\",\"N\",\"U\"]].notna().all(axis=1)\n",
    "    if ignore_first_per_flight and \"flight_id\" in df.columns:\n",
    "        first_idx = df.groupby(\"flight_id\").head(1).index\n",
    "        valid_ex = valid.copy(); valid_ex.loc[first_idx] = False\n",
    "    else:\n",
    "        valid_ex = valid\n",
    "    any_nz = valid_ex & (df[[\"E\",\"N\",\"U\"]].abs() > eps).any(axis=1)\n",
    "    all_nz = valid_ex & (df[[\"E\",\"N\",\"U\"]].abs() > eps).all(axis=1)\n",
    "    total = len(df); tot_valid = int(valid.sum())\n",
    "    return pd.Series({\n",
    "        \"total_rows\": total,\n",
    "        \"valid_rows\": tot_valid,\n",
    "        \"valid_pct\": (tot_valid/total*100.0) if total else 0.0,\n",
    "        \"any_nonzero_rows\": int(any_nz.sum()),\n",
    "        \"any_nonzero_pct_of_valid\": (int(any_nz.sum())/max(tot_valid,1)*100.0),\n",
    "        \"all_nonzero_rows\": int(all_nz.sum()),\n",
    "        \"all_nonzero_pct_of_valid\": (int(all_nz.sum())/max(tot_valid,1)*100.0),\n",
    "        \"ignored_first_rows\": int(valid.sum() - valid_ex.sum()) if ignore_first_per_flight and \"flight_id\" in df.columns else 0\n",
    "    })\n",
    "\n",
    "print(enu_counts(df_runs, eps=1e-6))\n",
    "print(enu_row_summary(df_runs, eps=1e-6, ignore_first_per_flight=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81c0349e-24a3-46b1-ad17-95b17c37201f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4j/b4y6wwhd0m18s4zqjd6p25mc0000gn/T/ipykernel_83205/1774761264.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(df_runs[c]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved with pyarrow → /Users/danielvillafuerte/weather-aware-trajectory-prediction/data/processed/flights_nativecadence_enu_kinematics.parquet\n",
      "\n",
      "Saved data summary:\n",
      "- Total rows: 1,038,555\n",
      "- Unique flights: 5,335\n",
      "- Continuous runs: 5,492\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Save Processed Data to Parquet\n",
    "from pathlib import Path\n",
    "\n",
    "# Create output directory\n",
    "out_path = repo_root / \"data\" / \"processed\" / \"flights_nativecadence_enu_kinematics.parquet\"\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Ensure no Period dtypes that can cause issues with parquet\n",
    "for c in df_runs.columns:\n",
    "    if pd.api.types.is_period_dtype(df_runs[c]):\n",
    "        df_runs[c] = df_runs[c].astype(str)\n",
    "\n",
    "# Try saving with pyarrow first, fallback to fastparquet\n",
    "saved = False\n",
    "\n",
    "try:\n",
    "    df_runs.to_parquet(out_path, index=False, engine=\"pyarrow\", compression=\"snappy\")\n",
    "    print(f\"✓ Saved with pyarrow → {out_path}\")\n",
    "    saved = True\n",
    "except Exception as e:\n",
    "    print(f\"pyarrow failed: {e}\")\n",
    "    \n",
    "if not saved:\n",
    "    try:\n",
    "        df_runs.to_parquet(out_path, index=False, engine=\"fastparquet\", compression=\"snappy\")\n",
    "        print(f\"✓ Saved with fastparquet → {out_path}\")\n",
    "        saved = True\n",
    "    except Exception as e:\n",
    "        print(f\"fastparquet failed: {e}\")\n",
    "        # Last resort: save as CSV\n",
    "        csv_path = out_path.with_suffix('.csv')\n",
    "        df_runs.to_csv(csv_path, index=False)\n",
    "        print(f\"✓ Saved as CSV fallback → {csv_path}\")\n",
    "\n",
    "# Summary of what we saved\n",
    "print(f\"\\nSaved data summary:\")\n",
    "print(f\"- Total rows: {len(df_runs):,}\")\n",
    "print(f\"- Unique flights: {df_runs['flight_id'].nunique():,}\")\n",
    "print(f\"- Continuous runs: {df_runs.groupby(['flight_id', 'run_id']).ngroups:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1333dde8-1f74-482a-8596-b06327ffd3cd",
   "metadata": {},
   "source": [
    "================================================================================\n",
    "DATA PREPARATION NOTEBOOK - OVERVIEW & OUTPUTS\n",
    "================================================================================\n",
    "\n",
    "STRATEGY:\n",
    "---------\n",
    "1. LOAD & CLEAN: Started with raw ADS-B data (06_12_17.csv) containing aircraft \n",
    "   position reports with many extraneous fields and potential quality issues.\n",
    "\n",
    "2. FLIGHT SEGMENTATION: Grouped continuous tracks by aircraft (icao24) and time,\n",
    "   creating new flights when gaps exceed 10 minutes. This handles cases where \n",
    "   the same aircraft appears multiple times in the dataset.\n",
    "\n",
    "3. QUALITY FILTERING: Kept only continuous runs with:\n",
    "   - At least 60 consecutive valid position reports\n",
    "   - Time gaps < 120 seconds between points\n",
    "   - Valid lat/lon/altitude throughout\n",
    "\n",
    "4. COORDINATE TRANSFORMATION: Converted global lat/lon/alt to local East-North-Up\n",
    "   (ENU) coordinates. Each flight segment uses its first point as the origin,\n",
    "   making trajectories translation-invariant for ML models.\n",
    "\n",
    "5. KINEMATICS COMPUTATION: Calculated velocities (vE, vN, vU) and turn rates\n",
    "   from position data, with outlier capping at realistic aviation limits:\n",
    "   - Max velocity: 680 m/s (Mach 2)\n",
    "   - Max turn rate: 0.5 rad/s (29 deg/s)\n",
    "\n",
    "OUTPUTS:\n",
    "--------\n",
    "- FILE: data/processed/flights_nativecadence_enu_kinematics.parquet\n",
    "- SIZE: ~1M rows, 5,492 continuous flight segments\n",
    "- COLUMNS: time, flight_id, run_id, lat, lon, alt, E, N, U, vE, vN, vU, \n",
    "          speed, heading_rad, turn_rate, dt, and metadata\n",
    "- QUALITY: 96% of rows have valid ENU data, ready for trajectory prediction\n",
    "\n",
    "KEY DECISIONS:\n",
    "--------------\n",
    "- Used 60-point minimum to ensure sufficient history for prediction\n",
    "- ENU coordinates enable position-invariant learning\n",
    "- Parquet format for efficient storage and fast loading\n",
    "- Preserved native ~10s cadence (will resample in model-specific notebooks)\n",
    "\n",
    "NEXT STEPS:\n",
    "-----------\n",
    "→ 02_ekf.ipynb: Physics-based Extended Kalman Filter baseline\n",
    "→ 03_lstm.ipynb: Data-driven LSTM approach  \n",
    "→ 04_compare.ipynb: Performance comparison with/without weather data\n",
    "================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6500aaea-6700-469e-9536-e9f24227eb31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
